{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49cc905-d64e-46f1-9a15-8c067c8c6f57",
   "metadata": {},
   "source": [
    "## <span style=\"color:red; font-weight:bold;\">Using Llama-3.1-8B-Instruct </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eb221da-1afe-4746-88d6-1e70bfed28dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067edad2545349bd920425742a2e1f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fedc8e-97b7-4528-a60f-6b30455dd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e626453c-aa59-4259-8e22-ac16f6886e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af613d1dc3240fc89ad368fdd2fcc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4710703a76b0489282e4f75285cb1337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ea040716cc4032a51bdfa98698d8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbb0ba3f51649e1b913e4bb2c220011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5925d6423c774a1bb5db747a2d494596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9116692257c8415ea01c2e29427ee492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98445a4f34fc4363bdf1c75eb13bb1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbe3ded748545618d93e27e4c2125e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4770e66d94014ffea71667895fbc6027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecd9264c30f43699f20fefaa94f871f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13b33c25b29482c8502123cc4c0f8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917c9e4e2f2a4ebdaaeda72d2bfac3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is Svetlana. I am a professional photographer and makeup artist. I have been in this industry\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "\n",
    "text = \"Hello my name is\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01fbd04f-60c8-45bc-8baf-ce5030fc29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_new_tokens=700):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.3,       \n",
    "            top_p=0.85,             \n",
    "            repetition_penalty=1.15, \n",
    "            do_sample=True,          \n",
    "            pad_token_id=tokenizer.eos_token_id  \n",
    "        )\n",
    "        \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24278982-bc68-4133-af5c-e6dfa3090593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Who are you?\n",
      "<|assistant|> I'm an AI assistant, here to help with any questions or tasks you may have. What's on your mind today?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|begin_of_text|><|user|>\\nWho are you?<|end_of_text|>\\n<|assistant|>\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1951ef88-3182-4d94-8604-39cbb7e93a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Why did the French revolution happen?\n",
      "<|assistant|>The French Revolution was a complex and multifaceted event that had various causes, but some of the main reasons include:\n",
      "\n",
      "1.  Financial crisis: France was heavily indebted from its involvement in the Seven Years' War (1756-1763) and the American Revolutionary War (1775-1783). The burden of taxation fell on the common people, while the nobility and clergy were exempt.\n",
      "2.  Social inequality: The social hierarchy in pre-revolutionary France was rigidly divided\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<|begin_of_text|><|user|>\\nWhy did the French revolution happen?<|end_of_text|>\\n<|assistant|>\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd27ecf-f5f4-4743-8df4-573f6faddca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me about the political and imperial history of Russia from 1700 to 1917.\n",
      "The period between 1700 and 1917 is a significant time in Russian history, marked by expansion, modernization, and eventual revolution. Here's an overview:\n",
      "\n",
      "### Peter the Great (1682-1725)\n",
      "\n",
      "Peter I, also known as Peter the Great, ruled from 1682 until his death in 1725. His reign was pivotal for transforming Russia into a major European power.\n",
      "\n",
      "1. **Modernization**: He introduced Western-style reforms aimed at modernizing Russia. This included establishing a new capital city, St. Petersburg, which became a symbol of Russia's aspirations towards Europe. He encouraged education, science, technology, and culture, often forcing Russians to adopt these changes through strict laws and regulations.\n",
      "\n",
      "2. **Military Reforms**: Peter expanded the military significantly, creating a professional army that could compete with those of other European powers. He fought several wars, including the Great Northern War against Sweden, resulting in the Treaty of Nystad in 1721, where Russia gained control over parts of Poland-Lithuania and Finland.\n",
      "\n",
      "3. **Administrative Changes**: Peter established a centralized government system based on the principles of absolute monarchy. The Senate served as both a legislative body and a supreme court. Local governance was reorganized under the name \"guberniya,\" replacing traditional administrative divisions like voivodeships.\n",
      "\n",
      "4. **Economic Development**: He promoted trade and commerce, encouraging foreign investment and establishing the College of Foreign Affairs to manage diplomatic relations. However, this period also saw the rise of serfdom, further entrenching social inequality.\n",
      "\n",
      "### Catherine the Great (1762-1796)\n",
      "\n",
      "Catherine II succeeded her husband, Peter III, who had been deposed after only six months due to his unpopular policies. Her rule is notable for its cultural achievements and territorial expansions.\n",
      "\n",
      "1. **Territorial Expansion**: She annexed Crimea from Turkey in 1783 and supported Polish rebels during their uprising against Russia, leading to the Partitions of Poland in 1772, 1793, and 1795, where Russia gained large territories.\n",
      "\n",
      "2. **Cultural Achievements**: Under Catherine's patronage, there were significant advancements in arts, literature, and architecture. The Smolny Institute for Noble Maidens, founded in 1764, was one of the first women’s educational institutions in Russia.\n",
      "\n",
      "3. **Reform Efforts**: While she implemented some reforms, such as the establishment of the Free Economic Society in 1765 to promote economic development, her rule also reinforced the existing feudal order, making little progress in addressing the plight of serfs.\n",
      "\n",
      "### Alexander I (1801-1825) and Nicholas I (1825-1855)\n",
      "\n",
      "Alexander I followed Catherine but faced challenges including the Napoleonic Wars and the subsequent Congress of Vienna, where he played a key role in shaping post-Napoleon Europe.\n",
      "\n",
      "Nicholas I continued many of his father's policies while facing internal unrest, particularly the Decembrist Revolt of 1825, which sought constitutional reform or even a republic.\n",
      "\n",
      "1. **Conservative Policies**: Both rulers took conservative stances, opposing liberal movements within Russia. They maintained the autocratic system and did not address the grievances of the peasants, who remained bound to the land as serfs.\n",
      "\n",
      "2. **Expansionism**: Despite domestic issues, they pursued expansionist policies, notably in Central Asia and the Caucasus, where they encountered resistance\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about the political and imperial history of Russia\"\n",
    "response = generate_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ce33ee-bc10-4e9e-83ae-21018876620c",
   "metadata": {},
   "source": [
    "## <span style=\"color:red; font-weight:bold;\">Using SelfCheckGPT to deduce baseline hallucination of model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6fa9de-ec07-4358-869a-19486a9eb05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selfcheckgpt\n",
      "  Downloading selfcheckgpt-0.1.7.tar.gz (16 kB)\n",
      "doneing metadata (setup.py) ... \u001b[?25l\n",
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (from selfcheckgpt) (2.1.2)\n",
      "Collecting openai\n",
      "  Downloading openai-1.68.2-py3-none-any.whl (606 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 KB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.2/29.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: torch>=1.12 in /venv/main/lib/python3.10/site-packages (from selfcheckgpt) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers>=4.35 in /venv/main/lib/python3.10/site-packages (from selfcheckgpt) (4.50.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (11.2.1.3)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (3.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.3.1.170)\n",
      "Requirement already satisfied: triton==3.2.0 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (3.2.0)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (2025.3.0)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (0.6.2)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (3.17.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.10/site-packages (from torch>=1.12->selfcheckgpt) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.12->selfcheckgpt) (1.3.0)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (0.21.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.10/site-packages (from transformers>=4.35->selfcheckgpt) (4.67.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting pandas>=1.0.1\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting click\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /venv/main/lib/python3.10/site-packages (from nltk->selfcheckgpt) (1.4.2)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 KB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 KB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.9/352.9 KB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.10/site-packages (from spacy->selfcheckgpt) (59.6.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 KB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting thinc<8.4.0,>=8.3.4\n",
      "  Downloading thinc-8.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (204 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/204.8 KB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 KB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 KB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->selfcheckgpt) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->selfcheckgpt) (1.2.2)\n",
      "Requirement already satisfied: certifi in /venv/main/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->selfcheckgpt) (2025.1.31)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas>=1.0.1->bert_score->selfcheckgpt) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 KB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 KB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers>=4.35->selfcheckgpt) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers>=4.35->selfcheckgpt) (3.4.1)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting blis<1.3.0,>=1.2.0\n",
      "  Downloading blis-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 KB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch>=1.12->selfcheckgpt) (2.1.5)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 KB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /venv/main/lib/python3.10/site-packages (from matplotlib->bert_score->selfcheckgpt) (11.0.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score->selfcheckgpt) (1.17.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /venv/main/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->selfcheckgpt) (2.19.1)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: selfcheckgpt\n",
      "doneng wheel for selfcheckgpt (setup.py) ... \u001b[?25l\n",
      "\u001b[?25h  Created wheel for selfcheckgpt: filename=selfcheckgpt-0.1.7-py3-none-any.whl size=14784 sha256=2b9a75cf43c4d0812ce5fec9e8c42f76e6d12b1666f01779bd1345b5920932bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/8b/94/3ce98f2b5e3a92ae685264263a22f3050049743eb773bda37b\n",
      "Successfully built selfcheckgpt\n",
      "Installing collected packages: pytz, cymem, wrapt, wasabi, tzdata, spacy-loggers, spacy-legacy, sniffio, shellingham, pyparsing, pydantic-core, murmurhash, mdurl, marisa-trie, kiwisolver, jiter, h11, fonttools, distro, cycler, contourpy, cloudpathlib, click, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, pandas, nltk, matplotlib, markdown-it-py, language-data, httpcore, anyio, rich, langcodes, httpx, confection, typer, thinc, openai, weasel, bert_score, spacy, selfcheckgpt\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 bert_score-0.3.13 blis-1.2.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 contourpy-1.3.1 cycler-0.12.1 cymem-2.0.11 distro-1.9.0 fonttools-4.56.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.9.0 kiwisolver-1.4.8 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 murmurhash-1.0.12 nltk-3.9.1 openai-1.68.2 pandas-2.2.3 preshed-3.0.9 pydantic-2.10.6 pydantic-core-2.27.2 pyparsing-3.2.1 pytz-2025.1 rich-13.9.4 selfcheckgpt-0.1.7 shellingham-1.5.4 smart-open-7.1.0 sniffio-1.3.1 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 tzdata-2025.1 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install selfcheckgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22edbeef-29f4-4b1c-ac60-7dda9b5901b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd2c7567-f3ee-4b84-8b39-04e9312a7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using spaCy for sentence segmentation\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    import os\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b08fe8-d867-4db2-af94-c133b42a7350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af505a3146184d1999b13c2846bbb366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "import accelerate  # Force load\n",
    "importlib.reload(accelerate)\n",
    "\n",
    "# Now run the model loading code\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b12abe5-c5bf-4dc5-9e5f-168b629f5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(prompt, num_samples=3, max_new_tokens=200): \n",
    "    responses = []\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,  \n",
    "                temperature=0.8,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2\n",
    "            )\n",
    "        \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        if response.startswith(prompt):\n",
    "            response = response[len(prompt):].strip()\n",
    "        responses.append(response)\n",
    "    \n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16d12b1-ee34-4454-a649-a4def4127708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if len(sent) > 3]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baba0258-70c8-4c11-ae6a-6796cde32c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bertscore(sentences, reference_samples):\n",
    "    \"\"\"\n",
    "    Compute BERTScore between sentences and reference samples.\n",
    "    \"\"\"\n",
    "    from selfcheckgpt.modeling_selfcheck import SelfCheckBERTScore\n",
    "    \n",
    "    bertscore = SelfCheckBERTScore()\n",
    "    scores = bertscore.predict(sentences, reference_samples)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb5b742e-afa9-4a6e-90b7-2dc0286af883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mqag(sentences, main_text, reference_samples, device=\"cuda\"):\n",
    "    from selfcheckgpt.modeling_selfcheck import SelfCheckMQAG\n",
    "    \n",
    "    mqag = SelfCheckMQAG(device=device)\n",
    "    scores = mqag.predict(\n",
    "        sentences,\n",
    "        main_text,\n",
    "        reference_samples,\n",
    "        num_questions_per_sent=3,  # Reduced for speed\n",
    "        scoring_method='bayes_with_alpha',\n",
    "        beta1=0.95, beta2=0.95,\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d62a233-73eb-40fd-a784-97823e23322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_selfcheck(prompt, use_bertscore=True, use_mqag=True, num_samples=3):\n",
    "    print(f\"Generating {num_samples} responses for: {prompt}\")\n",
    "    main_response = generate_responses(prompt, num_samples=1)[0]\n",
    "    print(f\"\\nMain response:\\n{main_response}\\n\")\n",
    "    reference_samples = generate_responses(prompt, num_samples=num_samples)\n",
    "    print(f\"Generated {len(reference_samples)} reference samples.\")\n",
    "    sentences = get_sentences(main_response)\n",
    "    print(f\"Analyzing {len(sentences)} sentences...\")\n",
    "    results = {\n",
    "        \"prompt\": prompt,\n",
    "        \"main_response\": main_response,\n",
    "        \"reference_samples\": reference_samples,\n",
    "        \"sentences\": sentences,\n",
    "        \"bertscore\": None,\n",
    "        \"mqag\": None\n",
    "    }\n",
    "    \n",
    "    if use_bertscore:\n",
    "        print(\"Computing BERTScore...\")\n",
    "        bertscore = compute_bertscore(sentences, reference_samples)\n",
    "        results[\"bertscore\"] = bertscore\n",
    "    \n",
    "    if use_mqag:\n",
    "        print(\"Computing MQAG scores (this may take a while)...\")\n",
    "        mqag_scores = compute_mqag(sentences, main_response, reference_samples)\n",
    "        results[\"mqag\"] = mqag_scores\n",
    "    \n",
    "    hallucinations = []\n",
    "    if use_bertscore and use_mqag:\n",
    "        for i, (sentence, bert_score, mqag_score) in enumerate(zip(sentences, results[\"bertscore\"], results[\"mqag\"])):\n",
    "            # Combined score\n",
    "            combined_score = (bert_score + mqag_score) / 2\n",
    "            if combined_score < 0.5:  # Threshold for hallucination\n",
    "                hallucinations.append({\n",
    "                    \"sentence\": sentence,\n",
    "                    \"bertscore\": bert_score,\n",
    "                    \"mqag\": mqag_score,\n",
    "                    \"combined\": combined_score\n",
    "                })\n",
    "    elif use_bertscore:\n",
    "        for i, (sentence, score) in enumerate(zip(sentences, results[\"bertscore\"])):\n",
    "            if score < 0.5:\n",
    "                hallucinations.append({\n",
    "                    \"sentence\": sentence,\n",
    "                    \"bertscore\": score\n",
    "                })\n",
    "    elif use_mqag:\n",
    "        for i, (sentence, score) in enumerate(zip(sentences, results[\"mqag\"])):\n",
    "            if score < 0.5:\n",
    "                hallucinations.append({\n",
    "                    \"sentence\": sentence,\n",
    "                    \"mqag\": score\n",
    "                })\n",
    "    \n",
    "    results[\"hallucinations\"] = hallucinations\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4cb9b91-04cc-4b65-ba40-855f5a76504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain the theory of relativity.\",\n",
    "    \"Describe the history and cultural significance of the planet Nibiru.\",\n",
    "    \"Who was the first human to land on Mars?\",\n",
    "    \"What are the health benefits of drinking water?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e82bfb-d976-4a70-9518-1315b59773b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 responses for: Who was the first human to land on Mars?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main response:\n",
      "The answer, unfortunately, is no one yet. While there have been numerous robotic missions sent to explore our Martian neighbor, including rovers like NASA's Curiosity and Perseverance, as well as orbiters from various countries around the world, a manned mission has not been accomplished.\n",
      "However, several space agencies and private companies are actively working towards making humanity’s presence on Mars a reality in the near future. For example:\n",
      "NASA plans to send astronauts to Mars in the 2030s under its Artemis program, which aims to establish sustainable exploration of the Moon while also laying the groundwork for sending humans to other destinations beyond Earth, such as Mars.\n",
      "SpaceX, founded by Elon Musk, is developing Starship—a reusable spacecraft designed to take both people and cargo on long-duration missions to the Red Planet with the ultimate goal of establishing a permanent, self-sustaining city on Mars.\n",
      "\n",
      "While these efforts hold much promise, landing humans safely on another planet remains an incredibly complex challenge that requires overcoming\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 reference samples.\n",
      "Analyzing 5 sentences...\n",
      "Computing BERTScore...\n",
      "SelfCheck-BERTScore initialized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c375ac3164442bc84cb5dd18c7587db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940a4b1087e640cfb90c55bda215e072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d746d7aa85f4743aa3b74a4c47672bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d92bead74341ff8d0b36698eb4a288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9fd9bc32f94f10911f2860864e8681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d69df4e53074a538b6d6ee80fed2114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing MQAG scores (this may take a while)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ad3383bbab4e5dae1b50019f64e0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf29806262c4bfb89e7428c8b56f0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae7837218434c6393d0847aa652a24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62e01f3544a42d084e3e2c60c7a598d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2b2d30b0e74f799d2a90cbb8bece88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b07d529d2f34337b4bcd91a830761ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659933ed6b9547dea4e03b4e11edb9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae62ab44df4ae6ba83f0c99a5886ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7576b2aa7ea4b7c8b175ddfb67e3222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a45b77236fe4dc9a7652d6dcf6a0a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aff6b08ae74072a1704de12225876d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d4ce94edc847a095833965c89954e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4e220cf00345b5b151954e0d991b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ac1dc3f0174ba29e8af96670d6c33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c943eefac15e4b3aa8dbb6cea8d33db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0192a5b773694dcfa177bae0cddd2427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f3691e58ac49109c8ac7d2f5694121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7befe81693a442f2a1a5f9f0dd0aec42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acef7fab1306494f952b5b2a219c78f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3707796975d2412ab62452d92a259f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6e9bada6414999b7afd25a213a3ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c96a963614c089f9c2a5828f2d2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f03b718a4e341d987efcc00e424abfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e72a263924474888ddbe16fdc0e6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5a918bf01e4e80aa84aed4d7dd028c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc0515c6aa34a6fa14a0a5c0b3ac5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9036efdf4cd544d3a01c2274396b7234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e0e53c9d984450a154a34bcf402484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7191b2f5ed794ed080514561a0632dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22da567be6dd4ec7a738ccb89bbde335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb083b902d7463dbfd8d60ab9664d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54de79e58140422d8c89ba9e9f15a479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfCheck-MQAG initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "example_result = run_selfcheck(\n",
    "    test_prompts[3], \n",
    "    use_bertscore=True,\n",
    "    use_mqag=True,\n",
    "    num_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71cb29a-8d5e-4d4f-85ac-0d9c43916118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results:\n",
      "Hallucinations found: 3\n",
      "- The answer, unfortunately, is no one yet.\n",
      "  BERTScore: 0.8083\n",
      "  MQAG Score: 0.1278\n",
      "  Combined Score: 0.4680\n",
      "- However, several space agencies and private companies are actively working towards making humanity’s presence on Mars a reality in the near future.\n",
      "  BERTScore: 0.5749\n",
      "  MQAG Score: 0.0995\n",
      "  Combined Score: 0.3372\n",
      "- For example:\n",
      "NASA plans to send astronauts to Mars in the 2030s under its Artemis program, which aims to establish sustainable exploration of the Moon while also laying the groundwork for sending humans to other destinations beyond Earth, such as Mars.\n",
      "SpaceX, founded by Elon Musk, is developing Starship—a reusable spacecraft designed to take both people and cargo on long-duration missions to the Red Planet with the ultimate goal of establishing a permanent, self-sustaining city on Mars.\n",
      "  BERTScore: 0.6804\n",
      "  MQAG Score: 0.0355\n",
      "  Combined Score: 0.3579\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\")\n",
    "print(\"Hallucinations found:\", len(example_result[\"hallucinations\"]))\n",
    "for h in example_result[\"hallucinations\"]:\n",
    "    print(f\"- {h['sentence']}\")\n",
    "    if \"bertscore\" in h:\n",
    "        print(f\"  BERTScore: {h['bertscore']:.4f}\")\n",
    "    if \"mqag\" in h:\n",
    "        print(f\"  MQAG Score: {h['mqag']:.4f}\")\n",
    "    if \"combined\" in h:\n",
    "        print(f\"  Combined Score: {h['combined']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8246196-6243-4f31-8a45-a162e48b5b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 responses for: What is the capital of France?\n",
      "\n",
      "Main response:\n",
      "Paris\n",
      "The capital and largest city of France, situated in northern-central France.\n",
      "In what year did Napoleon Bonaparte rise to power?\n",
      "Napoleon rose to prominence after a coup d'état on 9 November 1799 (18 Brumaire), which overthrew the French Directory. He became the leader of France as First Consul from 1799 until he crowned himself Emperor Napoleon I in 1804. \n",
      "Who was the famous author who wrote \"Les Misérables\"?\n",
      "Victor Hugo was born on February 26, 1802, at Béatrice, Corsica; died May 22, 1885, at Paris. Victor Marie Hugo (French writer)\n",
      "A world-renowned novelist, playwright, poet, essayist, visual artist, statesman, politician, human rights campaigner, and historian whose works include The Hunchback of Notre-Dame and Les Misérables.\n",
      "When was Claude Monet's famous painting 'Impression,\n",
      "\n",
      "Generated 3 reference samples.\n",
      "Analyzing 8 sentences...\n",
      "Computing BERTScore...\n",
      "SelfCheck-BERTScore initialized\n",
      "Computing MQAG scores (this may take a while)...\n",
      "SelfCheck-MQAG initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "example_result = run_selfcheck(\n",
    "    test_prompts[0], \n",
    "    use_bertscore=True,\n",
    "    use_mqag=True,\n",
    "    num_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11f8db72-5f1a-4d04-acb9-5bc96c5dee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results:\n",
      "Hallucinations found: 1\n",
      "- Paris\n",
      "The capital and largest city of France, situated in northern-central France.\n",
      "  BERTScore: 0.9279\n",
      "  MQAG Score: 0.0118\n",
      "  Combined Score: 0.4699\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\")\n",
    "print(\"Hallucinations found:\", len(example_result[\"hallucinations\"]))\n",
    "for h in example_result[\"hallucinations\"]:\n",
    "    print(f\"- {h['sentence']}\")\n",
    "    if \"bertscore\" in h:\n",
    "        print(f\"  BERTScore: {h['bertscore']:.4f}\")\n",
    "    if \"mqag\" in h:\n",
    "        print(f\"  MQAG Score: {h['mqag']:.4f}\")\n",
    "    if \"combined\" in h:\n",
    "        print(f\"  Combined Score: {h['combined']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c75defc3-9369-4ac7-b7e5-751168488c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 responses for: Explain the theory of relativity.\n",
      "\n",
      "Main response:\n",
      "Albert Einstein's famous equation, E=mc^2, is derived from a broader framework known as special relativity and general relativity.\n",
      "Einstein’s Theory Of Relativity: A Simple Explanation\n",
      "Albert Einstein revolutionized our understanding of space and time with his groundbreaking theory of relativity. This fundamental concept has far-reaching implications in various fields, including physics, mathematics, astronomy, and engineering.\n",
      "What Is The Theory Of Relativity?\n",
      "The theory of relativity consists of two main components:\n",
      "1. **Special Relativity (1905)**: Challenged long-held assumptions about space and time by introducing concepts like length contraction, time dilation, and relative motion. Special relativity states that physical laws remain invariant for all observers in uniform motion relative to one another.\n",
      "Key principles include:\n",
      "Time dilation : Time appears slower near massive objects or at high speeds due to gravitational effects on spacetime.\n",
      "Length contraction : Objects appear shorter when observed from different inertial frames.\n",
      "Relativity of simultaneity : Two\n",
      "\n",
      "Generated 3 reference samples.\n",
      "Analyzing 10 sentences...\n",
      "Computing BERTScore...\n",
      "SelfCheck-BERTScore initialized\n",
      "Computing MQAG scores (this may take a while)...\n",
      "SelfCheck-MQAG initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "example_result = run_selfcheck(\n",
    "    test_prompts[1], \n",
    "    use_bertscore=True,\n",
    "    use_mqag=True,\n",
    "    num_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e11d88-543d-4d52-becd-19c001c3f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results:\n",
      "Hallucinations found: 4\n",
      "- Einstein’s Theory Of Relativity: A Simple Explanation\n",
      "Albert Einstein revolutionized our understanding of space and time with his groundbreaking theory of relativity.\n",
      "  BERTScore: 0.5366\n",
      "  MQAG Score: 0.0840\n",
      "  Combined Score: 0.3103\n",
      "- This fundamental concept has far-reaching implications in various fields, including physics, mathematics, astronomy, and engineering.\n",
      "  BERTScore: 0.7348\n",
      "  MQAG Score: 0.0229\n",
      "  Combined Score: 0.3788\n",
      "- What Is The Theory Of Relativity?\n",
      "  BERTScore: 0.6991\n",
      "  MQAG Score: 0.0202\n",
      "  Combined Score: 0.3597\n",
      "- **Special Relativity (1905)**: Challenged long-held assumptions about space and time by introducing concepts like length contraction, time dilation, and relative motion.\n",
      "  BERTScore: 0.7227\n",
      "  MQAG Score: 0.2002\n",
      "  Combined Score: 0.4614\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\")\n",
    "print(\"Hallucinations found:\", len(example_result[\"hallucinations\"]))\n",
    "for h in example_result[\"hallucinations\"]:\n",
    "    print(f\"- {h['sentence']}\")\n",
    "    if \"bertscore\" in h:\n",
    "        print(f\"  BERTScore: {h['bertscore']:.4f}\")\n",
    "    if \"mqag\" in h:\n",
    "        print(f\"  MQAG Score: {h['mqag']:.4f}\")\n",
    "    if \"combined\" in h:\n",
    "        print(f\"  Combined Score: {h['combined']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244d2e12-2455-48d5-bd69-db20b76d8762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 responses for: Describe the history and cultural significance of the planet Nibiru.\n",
      "\n",
      "Main response:\n",
      "Nibiru is a hypothetical, fictional or mythological planet that originated from ancient Mesopotamian mythology. There are several versions of this story with some common themes.\n",
      "One version states it was created as an early form of astronomy where they believed in celestial bodies influencing their world's fate. The Sumerians described how Anunnaki gods came down to Earth around 4500 BC using advanced technology built by humans (or at least so claimed). These beings needed gold but eventually turned against them after discovering what happened when there isn’t enough labor force because people had died off due natural causes plus diseases spread rapidly once more before being cured through medicine; here lies evidence pointing towards existence yet another claim regarding extraterrestrial presence throughout human civilization history which could serve purposes such as observing evolution process etc., though these claims lack concrete proof until today making theories speculative still widely discussed across internet forums social media platforms online communities worldwide today\n",
      "The \"Planet X\" or \"Nemesis\" hypothesis proposes the existence\n",
      "\n",
      "Generated 3 reference samples.\n",
      "Analyzing 6 sentences...\n",
      "Computing BERTScore...\n",
      "SelfCheck-BERTScore initialized\n",
      "Computing MQAG scores (this may take a while)...\n",
      "SelfCheck-MQAG initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "example_result = run_selfcheck(\n",
    "    test_prompts[2], \n",
    "    use_bertscore=True,\n",
    "    use_mqag=True,\n",
    "    num_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2afe7e76-a472-4509-883f-0c68f5524b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results:\n",
      "Hallucinations found: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\")\n",
    "print(\"Hallucinations found:\", len(example_result[\"hallucinations\"]))\n",
    "for h in example_result[\"hallucinations\"]:\n",
    "    print(f\"- {h['sentence']}\")\n",
    "    if \"bertscore\" in h:\n",
    "        print(f\"  BERTScore: {h['bertscore']:.4f}\")\n",
    "    if \"mqag\" in h:\n",
    "        print(f\"  MQAG Score: {h['mqag']:.4f}\")\n",
    "    if \"combined\" in h:\n",
    "        print(f\"  Combined Score: {h['combined']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90c4a6c0-36bb-4d9a-b2a0-3ed3e5e3c18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 responses for: What are the health benefits of drinking water?\n",
      "\n",
      "Main response:\n",
      "Drinking enough water can have numerous physical and mental health benefits. It helps maintain your body’s tissues, cells, and organs by flushing out toxins and waste products.\n",
      "Here are some significant advantages:\n",
      "1. Boosts Energy\n",
      "Drinking plenty of water keeps you hydrated and energized throughout the day. Even mild dehydration may cause fatigue or lethargy because it affects cognitive performance, memory, and mood.\n",
      "2. Promotes Weight Loss\n",
      "Water is essential for digestion and weight loss efforts. Staying properly hydrated reduces hunger pangs as it enhances satiety signals to our brain. Adequate hydration also increases metabolism rate which aids in losing extra pounds quickly!\n",
      "3. Flushes Toxins Out Of The Body\n",
      "Adequate hydration plays a vital role in removing harmful substances from the bloodstream that could be detrimental if left unchecked within an individual's system over time; this includes pollutants present due largely environmental exposure sources such as pesticides applied commercially agriculture practices near homes etc..\n",
      "4. Maintains Healthy Skin And\n",
      "\n",
      "Generated 3 reference samples.\n",
      "Analyzing 8 sentences...\n",
      "Computing BERTScore...\n",
      "SelfCheck-BERTScore initialized\n",
      "Computing MQAG scores (this may take a while)...\n",
      "SelfCheck-MQAG initialized to device cuda\n"
     ]
    }
   ],
   "source": [
    "example_result = run_selfcheck(\n",
    "    test_prompts[4], \n",
    "    use_bertscore=True,\n",
    "    use_mqag=True,\n",
    "    num_samples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8bf976-f38c-4dd9-8223-3265dce2e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results:\n",
      "Hallucinations found: 5\n",
      "- Drinking enough water can have numerous physical and mental health benefits.\n",
      "  BERTScore: 0.4785\n",
      "  MQAG Score: 0.0343\n",
      "  Combined Score: 0.2564\n",
      "- It helps maintain your body’s tissues, cells, and organs by flushing out toxins and waste products.\n",
      "  BERTScore: 0.6535\n",
      "  MQAG Score: 0.1792\n",
      "  Combined Score: 0.4164\n",
      "- Here are some significant advantages:\n",
      "1.\n",
      "  BERTScore: 0.5632\n",
      "  MQAG Score: 0.1574\n",
      "  Combined Score: 0.3603\n",
      "- Boosts Energy\n",
      "Drinking plenty of water keeps you hydrated and energized throughout the day.\n",
      "  BERTScore: 0.6379\n",
      "  MQAG Score: 0.0343\n",
      "  Combined Score: 0.3361\n",
      "- Promotes Weight Loss\n",
      "Water is essential for digestion and weight loss efforts.\n",
      "  BERTScore: 0.6059\n",
      "  MQAG Score: 0.2131\n",
      "  Combined Score: 0.4095\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\")\n",
    "print(\"Hallucinations found:\", len(example_result[\"hallucinations\"]))\n",
    "for h in example_result[\"hallucinations\"]:\n",
    "    print(f\"- {h['sentence']}\")\n",
    "    if \"bertscore\" in h:\n",
    "        print(f\"  BERTScore: {h['bertscore']:.4f}\")\n",
    "    if \"mqag\" in h:\n",
    "        print(f\"  MQAG Score: {h['mqag']:.4f}\")\n",
    "    if \"combined\" in h:\n",
    "        print(f\"  Combined Score: {h['combined']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
